[{"content":"Hello, my name is Juhee Kim, and I am a PhD student at CompSec Lab, Department of Electrical and Computer Engineering, Seoul National University. I am advised by Byoungyoung Lee.\nMy research interests span a broad spectrum of software security issues and finding practical solutions. My recent research explores ARM\u0026rsquo;s Memory Tagging Extension (MTE), looking at how it can protect the systems and how it can be bypassed. I am also interested in the security of LLM agents and GPU/ML systems.\nI am looking for a summer internship in 2025. Please feel free to contact me if you are interested in working with me!\nUpdates TikTag has been accepted to IEEE S\u0026amp;P 2025! üéâ ü•≥ I will be speaking about TikTag at HARDWEAR.IO Netherlands 2024! My first paper, PeTAL, has been accepted to ACM CCS 2024! üéâ ü•≥ I presented the ARM MTE side-channel attack at Black Hat USA 2024! This talk will also be presented at Samsung Security Tech Forum 2024. Publications TikTag: Breaking ARM\u0026rsquo;s Memory Tagging Extension with Speculative Execution Juhee Kim, Jinbum Park, Sihyeon Roh, Jaeyoung Chung, Youngjoo Lee, Taesoo Kim, and Byoungyoung Lee IEEE Symposium on Security and Privacy (S\u0026amp;P) 2025 PeTAL: Ensuring Access Control Integrity against Data-only Attacks on Linux Juhee Kim, Jinbum Park, Yoochan Lee, Chengyu Song, Taesoo Kim, and Byoungyoung Lee ACM Conference on Computer and Communications Security (CCS) 2024 CHANCEL: Efficient Multi-client Isolation Under Adversarial Programs Adil Ahmad, Juhee Kim, Jaebaek Seo, Insik Shin, Pedro Fonseca, and Byoungyoung Lee Network and Distributed System Security Symposium (NDSS) 2021 Talks Bypassing ARM\u0026rsquo;s Memory Tagging Extension with a Side-Channel Attack Black Hat USA 2024 Samsung Security Tech Forum 2024 Education Ph.D. in Department of Electrical and Computer Engineering, Seoul National University 2020.03 - Present B.S. in Department of Electrical and Computer Engineering, Seoul National University 2015.03 - 2020.02 ","href":"/","title":"Home"},{"content":"","href":"/archive/","title":"Archive"},{"content":"From August 5th to 12nd 2024, I attended Black Hat USA 2024 (and Defcon 32) in Las Vegas. I presented my research on Bypassing MTE with a side-channel attack. I returned to Korea this morning (luckily, no jet lag) and am writing this post to share my experiences from Las Vegas before I forget them.\nBlack Hat USA 2024 First Black Hat experience I\u0026rsquo;ve never been to Black Hat before, so I was very excited, especially since I was going to present for the first time in an international conference. There were lots of people, great talks, and free food and drinks üíô. Some gifts were also given: a Black Hat backpack, which I found very practical and useful, a tumblr with a straw, and a badge.\nI also attended the speaker VIP party prior to the conference, where I had the chance to meet many researchers and security experts in person. It was so exciting to meet professionals I\u0026rsquo;ve only seen in papers.\nFor the sake of networking, I did try to connect with others, and I think it was quite successful. Since English is not my first language, it\u0026rsquo;s always challenging to communicate at such parties, but I was fairly able to communicate with others (shoutout to all my online English tutors!). However, I still feel like I need to expand my vocabulary to express my thoughts more clearly.\nRegarding the venue, it was huge, so I had to walk a lot. I was exhausted every day because I only brought shoes with hard soles. I should have brought more comfortable shoes for walking. The business hall had many company booths where I could get free t-shirts and other company swags. I wanted to visit more booths but couldn\u0026rsquo;t being busy with my talk and other things.\nDespite the venue\u0026rsquo;s size, the briefing sessions weren\u0026rsquo;t as crowded as I expected. I\u0026rsquo;ve heard that the briefings were usually packed (about 10 years ago), but the session halls had plenty of empty seats. I only saw people lining up once, for the \u0026ldquo;15 ways to Break your Copilot\u0026rdquo; talk (does everyone want to break Copilot?). But most talks weren\u0026rsquo;t even half full.\nAmong the 5-6 talks I attended, some were really interesting and tackled the specific subjects I\u0026rsquo;m working on at the moment. It assured me that I was doing relevant research, but it also made me think I need to push our projects harder to complete them before someone else does üòµ‚Äçüí´.\nI found LLM security talk by Richard Harang (Nvidia) very fascinating. Not only was the content excellent, but the way he presented was also very engaging.\nMy talk As a first-time speaker, I was quite nervous about my talk, especially since Black Hat is a non-academic conference with a large and diverse audience. Before the conference, my advisor and I had many discussions about the content and visuals to make it easy to follow for the general audience. We also had multiple rounds of rehearsals.\nAt the conference, before my talk, I had a scheduled interview with Dark Reading. I expected it to be a simple, brief session that would be published as an article later. But it turned out to be a news desk-style live interview with a camera crew! I was so nervous because I didn\u0026rsquo;t expect it to be live, and I hadn\u0026rsquo;t prepared for that at all. It was the most overwhelming experience I had on this trip. Well, I think I did my best, staying calm and answering the questions somehow\u0026hellip; üòÖ\nOn the day of the presentation, I felt quite confident\u0026ndash;maybe because I had practiced a lot and had already gone through the anxiety of the live interview. I was also kind of tired of being nervous since my talk was scheduled at the afternoon of the last day. So I thought, \u0026ldquo;I don\u0026rsquo;t care anymore. I just want to finish this.\u0026rdquo;\nThe talk went successful. I think I even enjoyed the feeling of being on stage and having the audience\u0026rsquo;s attention (?!). The audience seemed engaged in my talk (no one appeared to be dozing off or leaving the hall). Some gave me positive feedback afterward, which I greatly appreciated and made me feel all the effort was worth it. I received many questions as well and was genuinely happy to see that my research was interesting to many people.\nOverall, I really enjoyed presenting at Black Hat USA and highly recommend it. I loved the feeling of being on stage and all the speaker privileges from BlackHat. I definitely want to present at Black Hat again!\nOther experiences A few other things I did during the trip.\nGoogle 0x0g party During this trip, I attended the Google 0x0g party (Google Vulnerability Reward Program party). It was my first time attending such an event, and there were so many security engineers from Google and various companies. The party featured programs with talks and events, but it was mainly about networking and socializing. I got to meet people around the industry, and overall, it was a great experience.\nSince I had given my talk about bypassing MTE the day before, I had some conversations about it. Opinions on MTE were quite divided across the industry, even within Google. Some were very positive about MTE, while others are quite negative, with some suggesting that MTE could be deprecated (?). This was interesting to me because, in academia, particularly in systems security, MTE is generally considered as a promising direction for future security, as long as the cost is not too high. The cost is indeed a significant issue, but the Pixel 8 series has demonstrated that MTE\u0026rsquo;s performance overhead is negligible. I also have a paper under review that leverages MTE for attack mitigation. Unfortunately, it has gone through the review process at top-tier security conferences about 4-5 times, but no reviewer raised concerns about the feasibility of MTE as a defense so far.\nAnother interesting thing I picked up, not only from this party but also from other people I\u0026rsquo;ve met in the past, is that high-end IOT device manufacturers are generally more positive about MTE. I\u0026rsquo;ve heard that Amazon is considering MTE for their future devices, and I also learned at this event that Meta is considering MTE for future Oculus devices. I wonder if this is because they are less concerned about the performance or other costs? In any case, it seems our researches on MTE is still highly relevant to the industry, and I\u0026rsquo;m excited to see how it will be adopted in the future.\nDefcon 2024 Defcon felt a lot less organized than BlackHat. As a non-CTF player, I didn\u0026rsquo;t find much to do at Defcon. I mostly wandered around some of the villages and attended a talk about bypassing Copilot (again, by a different speaker). Then I spent some time at the Car Hacking Village, where my advisor was participating in the CTF üòÑ. I just watched him play and worked on my own stuff. By that point, I didn\u0026rsquo;t have much social energy left, so I tried to focus on getting back to my research.\nI also attended the AIxCC closing ceremony, where the winners of the AIxCC competition were announced. I heard the competition was quite intense, with participants dedicating a lot of time and resources. I was happy to see few teams I know win the competition and move on to the final round. I really wanted to see AI beat previous techniques like fuzzing and symbolic execution, but I think we\u0026rsquo;re not there yet. Would love to see more progress in this area!\nHotels \u0026amp; Pools I stayed at Mandalay Bay during Black Hat, and Fontainebleau during Defcon. Both hotels were great, close to each conference venue, and had nice pools.\nMandalay Bay was a classic hotel with a spacious room. It was a bit old-fashioned, but the room was clean and comfortable. The hotel was huge, and I had to walk a lot to get to the conference venue. I think I didn\u0026rsquo;t had enough time to explore the hotel during Black Hat, but I did enjoy their pool before checking out.\nMandalay\u0026rsquo;s pool was really nice. On Friday, before we checked out, we went to the pool, and surprisingly, there weren\u0026rsquo;t many people. With various pools\u0026ndash;wave pool, lazy river, and regular pool\u0026ndash;it was fun to hop around and enjoy the sun. Compared to wave pools in Korea, Mandalay\u0026rsquo;s had smaller waves, but they allowed people to swim in the deeper areas. While this seemed a bit dangerous for kids and non-swimmers, I actually had fun swimming in the pool where my feet couldn\u0026rsquo;t touch the ground.\nWe wanted to visit Mandalay Bay\u0026rsquo;s pool again after checking out, so we returned on Monday morning, paying $25 for per person for a pool pass üòÇ. However, Monday was much more crowded, and I couldn\u0026rsquo;t enjoy the pool as much as I did on Friday. Maybe it was because the price was cheaper on Monday, or perhaps because Black Hat has ended and many people were staying at the hotel for vacation. Still, I enjoyed the pool and got a bit of tan üòé.\nFontainebleau was much more luxurious than Mandalay Bay. I had seen some reviews mentioning that the rooms weren\u0026rsquo;t always well-cleaned, but our room was okay\u0026ndash;maybe not perfect, but acceptable. The room was a bit smaller than at Mandalay Bay, but the facilities were much newer and cleaner. They even had USB-C ports on the wall!\nFontainebleau\u0026rsquo;s pool was also nice. Although they didn\u0026rsquo;t have a variety of pools like Mandalay Bay, the pool was clean and not too crowded. They also offered free parasols for sunbeds! I had a great time swimming and relaxing at the pool.\nDespite its expensive image, some restaurants at Fontainebleau were good and reasonably priced, considering the usual costs in Las Vegas. Our favorite was a Hong Kong-style restaurant called \u0026ldquo;Washing Potato\u0026rdquo;. We had lunch there twice to enjoy dim sum and noodles üòã.\nCasinos I thought I wouldn\u0026rsquo;t be a fan of casinos, but I actually liked playing the games. I played blackjack and roulette, mostly at Fontainebleau, and ended up broke üòÇ. I realized that I\u0026rsquo;m not good at gambling because I\u0026rsquo;m too optimistic, which is great for research but not for gambling. In games like these, it\u0026rsquo;s obvious that you\u0026rsquo;ll lose in the long run, but I kept thinking I could win. Perhaps I should learn how to play poker instead (?!). Maybe next time! üòÑ\nConclusion I had a nice time in Las Vegas, although at times the place felt a bit too crazy for me. I loved my experience at Black Hat USA. I enjoyed presenting my research, meeting people, and learning about the latest security trends in research and industry. It definitely motivated me to work harder on my research and return to Las Vegas as a speaker again!\n","href":"/posts/bhusa24/","title":"Black Hat USA 2024"},{"content":"","href":"/tags/blackhat/","title":"BlackHat"},{"content":"","href":"/categories/","title":"Categories"},{"content":"","href":"/tags/mte/","title":"MTE"},{"content":"","href":"/posts/","title":"Posts"},{"content":"","href":"/categories/research/","title":"Research"},{"content":"","href":"/tags/","title":"Tags"},{"content":"It\u0026rsquo;s the end of 2023, and as I look back on the year, I can only say that it was a year full of research. I remember the days spent in front of the computer, reading papers, and conducting experiments. Of course, there were other events this year, including the creation of this blog (yay!). So, I decided it would be nice to write a review of 2023, to reflect on this year and to prepare for the next year.\nSurprises of 2023 Things that happened in 2023 that I didn\u0026rsquo;t expect.\nA new research topic - LLM security The most significant technical surprise of 2023 might be the development of ChatGPT. I found ChatGPT and its use of plugins, along with its interaction with Non-ML programs, to be very interesting. I decided to investigate more on this topic and realized it was a new research area that I could work on. Delving into this topic, I somehow ended up understanding more about old-school security models and information flow control. This even led me to gain deeper understanding on the security papers I read previously. Currently working on other projects, but I am eager to continue on this topic as soon as I finish them!\nNew research collaboration. This year, I was fortunate to have a new collaboration with excellent researchers to enhance the previously rejected paper. I am very proud of the work we did together and hope that it will be accepted. It was a great experience. Lesson learned: Reaching out brings new opportunities.\nAnother new research topic - ARM MTE side-channel From the previous collaboration, I also got a chance to work on a new research topic: ARM MTE side-channel (officially disclosed this month!) I am very excited on this project, and I hope that we can complete it with a good result.\nTriumphs of 2023 Things that I am proud of in 2023.\nMorning routine I have been trying to wake up early for a long time. Starting a day early is a common advice for productivity, and for me, it was about avoiding the morning traffic jam in Seoul. The only working solution was the morning exercise routine. I enjoyed morning swimming from March to November and switched to yoga from December. This habit allows me to arrive at the lab earlier than others and have my own time focusing on my work. I\u0026rsquo;m very pleased with this routine and hope to continue it next year. I believe no one who knows me would believe that I am now a morning person. Still, I ocassionally oversleep, so my goal for the next year is to establish a more consistent morning routine.\nNew blog I launched this blog this summer. Although I haven\u0026rsquo;t written much yet, it is good to have a place to write. I admit that I am still shy about sharing my ideas publicly, and I haven\u0026rsquo;t managed to write regularly. However, I hope to write more in the next year.\nStudying English I re-joined the English speaking group I participated years ago and felt my English has quite improved. I consistently took italki lessons as well. One day, I accidentally joined a group class for C1 level students. The students really challenged me, letting me realize that I still have a long way to go.\nUnfulfilled goals of 2023 Things that I wanted to do in 2023 but failed to do so.\nGetting paper accepted The paper I submitted this year faced rejection, despite I believed I had done everything I could. It was a puzzling result. My advisor reassured me that it was a good paper and if I keep working on it, it would be accepted one day.. Anyway, I quickly re-submitted to another venue. After that, I realized my previous rejection was due to failing to satisfy one reviewer\u0026rsquo;s seemingly trivial demands. It is painful to go through another round of review process, and it was a worthwhile lesson learned. With several other interesting projects in progress, I am optimistic that I\u0026rsquo;ll have more opportunities to achieve this goal in the coming year.\nOthers Reading books: Started multiple books but failed to finish any of them..;-) Consistent wake-up time: My sleep schedule is still inconsistent. Establishing a consistent sleep schedule is next year\u0026rsquo;s goal. Being nice to others: This one wasn\u0026rsquo;t actually planned, but I realized this year it would be beneficial to everyone if I am a bit nicer. ","href":"/posts/2023-review/","title":"A review of 2023: Surprises, Triumphs, and Failures"},{"content":"","href":"/categories/graduate-life/","title":"Graduate Life"},{"content":"","href":"/tags/productivity/","title":"productivity"},{"content":"Time flies in graduate school! Having spent 3.5 years as a PhD student, one thing I\u0026rsquo;ve learned is that I should be super-efficient in managing my time and energy.\nI\u0026rsquo;m not someone you\u0026rsquo;d label as \u0026ldquo;born productive\u0026rdquo;. I\u0026rsquo;m a typical \u0026ldquo;P\u0026rdquo;-type person according to Myers-Briggs Type Indicator (MBTI)\u0026ndash;indicative of a spontaneous and flexible nature. As many P-type people do, I\u0026rsquo;m prone to distraction and have difficulty in sticking to routines. Daily to-do lists or planners are ways to self-torture by confining free will into a fixed schedule. I also sleep a lot and have a hard time waking up early.\nIn my undergraduate years, I\u0026rsquo;d often find myself pulling all-nighters to finish assignment projects and study for the exams. Yet, despite this approach, I managed to get average grades and was lucky enough to join an awesome research group for my PhD.\nResearch, however, is a different game. It demands consistent and sustained effort\u0026ndash;ideation, problem-solving, experimentation, and writing a paper. Especially when you are targeting top-tier conferences, they would require creativity and novelty in your work, which cannot be achieved over a single night. Speed is essential too; the review process takes months and there\u0026rsquo;s always a chance that you are not the only one who thought of the same idea.\nWhat\u0026rsquo;s more, graduate life is not only about research. There are classes, seminars, TAs, meetings, conferences, paperwork, and so on. Of course, you also have to study English and maintain your health and social life.\nIn the first two years of PhD, I was either busy working overnight to meet the deadlines or wasting my time on random things that intrigued my interest yet were not so important. I was constantly stressed out and felt that I was not productive enough. I was also nervous about my academic performance and my future career since I was not sure if I could finish my PhD with good publications.\nIn 2022, my third year, I decided to bring some change to my life. I experimented with various productivity strategies from experts to find what worked for me. Today, while I\u0026rsquo;m still in exploration, I discovered several ways that boost my productivity. While there\u0026rsquo;s no assurance that they\u0026rsquo;ll bring me a list of high-quality papers, at least I feel I have done my best of what I can do. No more regrets.\nThrough this series, I\u0026rsquo;ll share some productivity insights that have proven to work for me. I hope this series helps some readers who are struggling with their productivity concerns.\nSide Note: Took the MBTI test again and I\u0026rsquo;m now 57% J-type. I guess I\u0026rsquo;m going in the right direction? :)\n","href":"/posts/series-productivity/","title":"Series: Graduate School Productivity - Introduction"},{"content":" Introduction In recent years, emerging technology in Machine Learning and Large Language Model (LLM) had led to the development of ML/LLM-powered applications. One of the popular service for ML/LLM application is Hugging Face. In this post, I would like to describe the potential security risks in current Hugging Face, especially in Spaces.\nHugging Face Hugging Face is a AI community that provides a lot of machine learning models, datasets, and applications. Users can contribute their own models, datasets, and demo applications (i.e., Spaces) to the community. This community has been growing rapidly since the advent of the transformer model.\nSpecifically, Spaces offers a easy-to-user environment to manage and host demo applications for models. Users can upload and deploy Spaces, which is then served as MLaaS (Machine Learning as a Service) from Hugging Face\u0026rsquo;s server. Spaces support various interface SDKs (Gradio, Streamlit) and execution environment options with various GPU accelerators.\nSecurity Risks on Spaces Despite its usability, Spaces incorporates several vulnerable designs, which may potentially lead to security issues.\nVuln. Design 1: Unrestricted App Logics First, Spaces allow users to upload and distribute any kind of apps. This unrestricted deployment introduces potential unsafe data-flows between the user and the app (or the execution environment). Specifically, arbitrary code execution and information leakage.\nIssue 1: Arbitrary Code Execution By its nature, Spaces allow arbitrary code execution from app developers to Hugging Face server. Developers can run any app on Hugging Face\u0026rsquo;s server just by uploading the app to Spaces. Moreover, if the app contains data-flows from user input to executable data (e.g., user-provided functions or shell commands), it would allow arbitrary code executions from app users to the server. If the app is publicly available, the arbitrary code execution functionality would be exposed to unspecified and anonymous users.\nWith proper containerization, the effect of arbitrary code execution is limited to the sandboxed environment. However, if a container escape vulnerability might allow the attacker to attempt container escape attack, which would further enable attacks on the host server.\nArbitrary code execution also allows attackers to change app\u0026rsquo;s behavior or hijack the goal. One example is bypassing any security measurement (e.g., safeguard prompts, throughput). With arbitrary execution, the attackers can delete or replace the safeguard prompts passed to the model, or they can nullify the restrictions on users such as throughput.\nAnother example is replacing the model used by the app with different model (e.g., backdoor-injected model, model for different tasks). Considering high-end GPU acceleration environment charge extra costs for the app developer, such attempts might also yield financial loss.\nReal-World Example shell is a simple app that takes user input and passes it to a langchain tool called ShellTool, which runs the input as a shell command. By sending commands, users can explore or manipulate the execution environment. For instance, sending ls as the command input would return the actual file in the containerized environment.\narbitrary shell command execution in Hugging Face Spaces\nIssue 2: Information Leakage between App and User Many apps in Spaces operate with numerous user-provided sensitive data. Apps require user credentials (e.g., API keys, ID, password) as a delegate for API uses. Apps require personal information (e.g., name, email, location) to provide customized services. When processing such data, apps should be safely designed to protect personal information. Recent privacy regulations (e.g., GDPR, CCPA) consider any user-provided input passed to web apps as sensitive data and enforces that appsq should not store nor track such data without user content.\nLacking restriction on app internal logics may allow dataflow from the users to untrusted channels. When user data is passed to an app, the app should carefully process the data for the intended operations only. However, as Spaces allow any apps with any logic to be deployed, we cannot assure whether the apps are properly handling user data.\nReal-World Example nlp-goemotions-senti-pred is a demo app for a sentiment prediction model, which allows user to input text and receive sentiment predictions from the model. For instance, if a user inputs \u0026ldquo;I trust you\u0026rdquo;, the app will return \u0026ldquo;agreement\u0026rdquo; as the predicted sentiment.\nnlp-goemotions-senti-pred predicts sentiment from input sentence\nHowever, there is a hidden functionality in this app that logs every user input and updates it to a public Huggingface dataset maintained by the app-developer. Consequently, every text provided by users is leaked and publicly exposed. The app does not inform users about this background activity, leaving them unaware of their data being logged into a dataset.\nUser input is silently logged into another dataset\nVuln. Design 2: Missing Isolation between Requests Another vulnerable design in Spaces is the lack of sufficient isolation between user requests. Currently, Spaces uses a single container when running an app. Therefore, every request made to the app, regardless of the sender, is executed within the same container environment. This can lead to unsafe data-flows between users, such as information leakage.\nIssue 3: Information Leakage between Users As Spaces provide a single container per app, it is crucial to ensure that user data is not shared between requests. If an app has a data-flow that stores user input to global states and then loads those global states into user-visible outputs, the app becomes vulnerable to user information leakage.\nTo illustrate this vulnerability, let\u0026rsquo;s take an example using shell. If a user executes the command echo \u0026quot;12345\u0026quot; \u0026gt; file \u0026amp;\u0026amp; ls, the app will create a file named file with 12345 and list the existing files in the current directory.\nSpaces allow apps to store user data as a global state (e.g., file)\nThen, another user can access the file by sending commands. An arbitrary user can read file by passing cat file to the app, thus leaking the data provided by the previous user.\nSharing a container between requests allows users to leak other users\u0026rsquo; data\nReal-World Example Chatbot-Blenderbot is a chat bot app that, upon receiving a user request, runs a model and saves every user input and model response to a file. The entire file, including inputs from other users, is then displayed to the user. However, this app does not notify users that their input will be logged and exposed to other users. Users only become aware that their input is being shared with others after they have already sent their data to the app.\nChatbot-Blenderbot exposes every input from different users without user consent\nConclusion I reported these issues to Hugging Face security team through email and Hugging Face forum. They didn\u0026rsquo;t replied the email but did show interest in addressing the issues through the forum. Unfortunately, they have not yet provided any working solutions or mitigation measures.\nAs we are in the initial stage of ML/LLM app development, there are several security vulnerabilities similar to those commonly studied in non-ML programs. One good news is that current ML/LLM apps are mostly for performing simple tasks like text/image transformation or chatbot functionalities, which are less prone to severe security vulnerabilities. Nonetheless, as this field continues to develop rapidly, applications will become complex, and a wide range of security issues are likely to emerge.\n","href":"/posts/hugging-evil-face/","title":"Hugging (Evil) Face: Security issues in Hugging Face"},{"content":"","href":"/tags/hugging-face/","title":"Hugging Face"},{"content":"","href":"/tags/kernel/","title":"kernel"},{"content":"","href":"/tags/llvm/","title":"LLVM"},{"content":"","href":"/tags/qemu/","title":"QEMU"},{"content":"Intro In the first year of my Ph.D, I ambitiously began a research on protecting the Linux kernel against data-only attacks. My research especially focused on protecting security-critical objects and pointers leveraging the ARM\u0026rsquo;s upcoming hardware security features (PAC and MTE).\nBuilding such a kernel hardening system required me to tackle several key issues:\nCross-compiling the kernel (X86 -\u0026gt; ARM64) Cross-module kernel analysis Linux kernel instrumentation Connecting the cross-module analysis with kernel build system. Setting up ARM64 environments for both emulation and a real device (Raspberry Pi 4B). As someone who was not well familar with kernel and compiler, each of these issues presented quite a challenge. So I thought it would be nice to write about each of the issues to help others facing similar issues.\n0. Environment My environment was as follows:\nHost Environment: Linux 5.15 Ubuntu 20.04.3 Clang/LLVM: 11.0.0 and 14.0.0 GNU Toolchain: aarch64-none-linux-gnu Qemu 5.1.0 Raspberry Pi 4B (4GB) 1. Building Kernel As the target system is AArch64 architecture and the host system is x86_64, the kernel needs to be cross-compiled from x86_64 to AArch64. At first, I expected Clang/LLVM would be able to do this job with -march option, as it is natively a cross-compiler. However, there was some problems related to the known cross compilation issues of Clang/LLVM. As described in ClangBuiltLinux and a blog, using ARM\u0026rsquo;s GNU toolchain (aarch64-none-linux-gnu) solves the problem.\nThe final script I used to cross-compile the kernel:\n#!/bin/bash -ve PROJ_DIR=${PWD}/.. LLVM_BUILD=${PROJ_DIR}/build/bin BINUTIL=~/util/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin export PATH=${BINUTIL}:$PATH:${LLVM_BUILD} export LLVM_COMPILER=clang export KERNEL=kernel8 export KCFLAGS=\u0026#34;-march=armv8.5-a \u0026#34; pushd ../linux-5.5 BINUTILS_TARGET_PREFIX=aarch64-none-linux-gnu make \\ ARCH=arm64 CROSS_COMPILE=aarch64-none-linux-gnu- \\ HOSTCC=clang CC=clang -j12 popd 2. Cross-module kernel analysis To identify every instructions accessing the protection target, a cross-module data-flow analysis is performed. Here, module indicates a single C file. One approach is to use wllvm to generate a single LLVM bitcode file of the entire kernel (i.e., vmlinux.bc). Here, some kernel modules containing duplicate symbol names may occur linking errors. Such files can be manually excluded from vmlinux.bc as explained in this blog, while such modules will be excluded from the analysis.\nOnce vmlinux.bc is generated, a custom LLVM analysis pass can be applied to it, enabling the cross-module analysis. The analysis pass is implemented as a LLVM pass plugin, which is loaded by opt command. Given a list of protection target (e.g., struct types, named global variables), the analysis pass identifies the memory access instructions (i.e., load/store, copy, alloc/free) that access the protection target.\n3. Linux Kernel Instrumentation The instrumentation is applied during kernel build on the instructions identified from the analysis. The LLVM tutorial on writing a LLVM pass introduces writing a LLVM pass as a plugin tool for opt command. However, the kernel build system uses CC (clang) and LD (lld) to build the kernel, instead of opt.\nOne approach is -Xclang option to pass the instrumentation pass as a Clang pass plugin. However, for some technical reasons that I cannot recall precisely, I did not choose this approach. It may have been due to uncertainty regarding whether every module would be built with the instrumentation pass.\nAnother approach that I took is to implement the instrumentation pass as a sanitizer, which is well-supported by both Linux and clang with -fsanitize=\u0026lt;sanitizer-name\u0026gt; option. Sanitizers are implemented as LLVM passes and are automatically loaded by clang. Existing sanitizers can be found in llvm-project/llvm/lib/Transforms/Instrumentation.\nTo add a new sanitizer, several modifications were made to Clang/LLVM and this change can be found in my github repo.\nThe final script to build the kernel with the instrumentation:\n#!/bin/bash -ve PROJ_DIR=${PWD}/.. LLVM_BUILD=${PROJ_DIR}/build/bin BINUTIL=~/util/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin export PATH=${LLVM_BUILD}:${BINUTIL}:$PATH export LLVM_COMPILER=clang export KERNEL=kernel8 export KCFLAGS=\u0026#34;-march=armv8.5-a -fsanitize=kdfi_instrument \u0026#34; pushd ../linux-5.5-kdfi BINUTILS_TARGET_PREFIX=aarch64-none-linux-gnu make \\ ARCH=arm64 CROSS_COMPILE=aarch64-none-linux-gnu- \\ HOSTCC=clang CC=clang -j12 popd 4. Connecting Analysis and Instrumentation Now the kernel can be analyzed and instrumented, but there is one more issue to solve: how do we connect the analysis and the instrumentation? A single LLVM pass for both analysis and instrumentation would be ideal. However, the kernel, as most C/C++ projects do, builds each module separately and links them together, which makes it difficult to perform cross-module analysis during kernel build.\nTo address this, I came up with a two-pass approach: One pass is for cross-module analysis that extracts the list of instructions from a pre-compiled whole-kernel bitcode (vmlinux.bc). Another is for instrumentation that is applied to each module to perform instrumentation for the previous identified instructions.\nThis requires a way to share the list of instructions between the two LLVM passes. Here, I simply used a simple text file containing raw dump of instructions in LLVM IR format. Each instruction is accompanied by minimal metadata such as function name and the instruction\u0026rsquo;s order in the function to accurately specify the intended instruction. While this method works, I believe there are more elegant ways to share the instructions between two passes.\nAdditionally, to avoid generating an excessively large file by dumping every instruction that need to be instrumented, a simple filter in the analysis pass excludes dumping instructions if they can be identified within each module. Consequently, the instrumentation pass also performs a simple intra-module analysis to identify the instructions filtered out from the list.\n5. Arm64 Environment Setup I used two types of testing environments: QEMU and Raspberry Pi 4B (4GB). QEMU is used for debugging and security evaluation, while Raspberry Pi is used for performance evaluation.\nFor the QEMU environment, I used buildroot (v2022.02.03) to build a root file system. The entire command to run QEMU is as follows:\nLINUX=$1 sudo ~/util/qemu-5.1.0/aarch64-softmmu/qemu-system-aarch64 \\ -machine virt,mte=on \\ -cpu max \\ -nographic -smp 1 \\ -hda /home/juhee/project/ppac/buildroot-2022.02.3/output/images/rootfs.ext4 \\ -kernel $LINUX/arch/arm64/boot/Image \\ -append \u0026#34;console=ttyAMA0 root=/dev/vda oops=panic panic_on_warn=1 panic=-1 ftrace_dump_on_oops=orig_cpu debug earlyprintk=serial slub_debug=UZ nokaslr \u0026#34; \\ -m 2G \\ -net user,hostfwd=tcp::10023-:22 \\ -net nic -s -S The emulated kernel can then be debugged with aarch64-none-linux-gnu-gdb.\nTo build the kernel for Raspberry Pi, I used the official Raspberry Pi firmware for the boot files and modules. The following script builds and prepares the boot files and modules of the instrumented kernel:\n#!/bin/bash -ve PROJ_DIR=${PWD} LLVM_BUILD=${PROJ_DIR}/build/bin BINUTIL=~/util/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin export PATH=${LLVM_BUILD}:${BINUTIL}:$PATH export LLVM_COMPILER=clang export KERNEL=kernel8 export KCFLAGS=\u0026#34;-fsanitize=kdfi_instrument \u0026#34; pushd linux-rpi-6.0-$1 BINUTILS_TARGET_PREFIX=aarch64-none-linux-gnu make \\ ARCH=arm64 CROSS_COMPILE=aarch64-none-linux-gnu- \\ CFLAGS=\u0026#34;-march=armv8-a+crc -mtune=cortex-a72\u0026#34; \\ CXXFLAGS=\u0026#34;-march=armv8-a+crc -mtune=cortex-a72\u0026#34; \\ HOSTCC=clang CC=clang -j10 \\ bindeb-pkg Image modules dtbs BINUTILS_TARGET_PREFIX=aarch64-none-linux-gnu make \\ ARCH=arm64 CROSS_COMPILE=aarch64-none-linux-gnu- \\ HOSTCC=clang CC=clang -j10 \\ CFLAGS=\u0026#34;-march=armv8-a+crc -mtune=cortex-a72\u0026#34; \\ CXXFLAGS=\u0026#34;-march=armv8-a+crc -mtune=cortex-a72\u0026#34; \\ INSTALL_MOD_PATH=../modules-$2 \\ modules_install cp arch/arm64/boot/Image ../boot-$2/kernel8.img cp arch/arm64/boot/dts/overlays/*.dtbo ../boot-$2/overlays cp arch/arm64/boot/dts/overlays/README ../boot-$2/overlays cp arch/arm64/boot/dts/broadcom/*.dtb ../boot-$2/ popd tar -cvf modules-$2.tar.gz modules-$2/ tar -cvf boot-$2.tar.gz boot-$2/ *.deb The boot files and modules can be sent to the Raspberry Pi with network, and then can be installed with the following script:\n#!/bin/bash -ve rm *.deb tar -xvf boot-$1.tar.gz sudo rm -r /boot/* sudo dpkg -i linux-headers-*.deb linux-image-*.deb linux-libc-*.deb sudo cp -r boot-$1/* /boot/ sudo cp *.txt /boot/ tar -xvf modules-$1.tar.gz sudo cp -r modules-$1/lib/* /lib/modules/ Conclusion This post described the issues I faced when building a security hardening system for the Linux kernel. I hope this post will be helpful for others facing similar issues.\n","href":"/posts/linux-arm64-hardening/","title":"Security-hardening ARM64 Linux kernel"},{"content":"","href":"/categories/","title":"Categories"},{"content":"","href":"/page/","title":"Pages"},{"content":"","href":"/authors/","title":"Authors"},{"content":"","href":"/tags/config/","title":"Configuration"},{"content":"","href":"/categories/graduate-life/","title":"Graduate Life"},{"content":"","href":"/tags/og/","title":"Opengraph"},{"content":"","href":"/categories/research/","title":"Research"},{"content":"","href":"/search/","title":"Search"},{"content":"","href":"/series/","title":"Series"}]
