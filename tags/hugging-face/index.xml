<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hugging Face on juppytt&#39;s blog</title>
    <link>/tags/hugging-face/</link>
    <description>Recent content in Hugging Face on juppytt&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="/tags/hugging-face/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Security Risks in Hugging Face Spaces</title>
      <link>/posts/huggingface-space-isolation/</link>
      <pubDate>Wed, 19 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>/posts/huggingface-space-isolation/</guid>
      <description>Introduction In recent years, emerging technology in Machine Learning and Large Language Model (LLM) had led to the development of ML/LLM-powered applications. One of the popular service for ML/LLM application is Hugging Face. In this post, I would like to describe the potential security risks in current Hugging Face, especially in Spaces.
Hugging Face Hugging Face is a AI community that provides a lot of machine learning models, datasets, and applications.</description>
    </item>
    
  </channel>
</rss>
